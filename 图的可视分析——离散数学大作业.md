# 图的可视分析——离散数学大作业

## 简介

该项目使用**Python**的**request**+**beautifulsoup**库和**selenium**库从萌娘百科(<a href="https://zh.moegirl.org">https://zh.moegirl.org</a>)爬取有关声优及动漫的数据，利用**Python**对数据进行整理、格式化，从数据中抽象出节点、边的信息并以**json**文件的格式导出，利用**Unity**实现图的可视化，为了配合**Unity**的可视化使用了**C#**实现了最短路径和最小生成树算法。

## 成员信息

* **卢鹏**  计96  2019011331
*  

## 成员分工

**卢鹏**负责数据的收集、数据的整理以及最短路径、最小生成树两个算法的实现。**杨骐瑞**负责图的可视化的实现。就语言来说，**卢鹏**完成了**Python**部分和一部分**C#**代码，**杨骐瑞**完成了大部分**C#**代码和**Unity**代码。

## 完成过程

* #### 数据收集

  编写程序，从萌娘百科动画总分类页（<a href="https://zh.moegirl.org/动画#">https://zh.moegirl.org/动画#</a>）进入各个时段动画分类页，爬取各部动画的声优表，并将原始数据存储在**data.txt**中。这部分实现见源文件中的**anime.py**文件。
  为了获得权重计算的相关数据，使用了**Python**的**selenium**库从百度百科(<a href="https://www.baike.baidu.com">www.baike.baidu.com</a>)爬取了动画的浏览记录信息来衡量动画的重要性。这部分实现见源文件中的**get_weight.py**文件。
  为了得到节点（声优）相关的图片和介绍信息，使用了**Python**的**selenium**库从萌娘百科（网址见上）爬取了声优的图片和介绍信息。这部分实现见源文件中的**parse_data.py**中的**net_info**函数。

* #### 数据格式化

  编写程序，将原始数据中不合规范的数据剔除，并将原始数据进行抽象，以声优作为节点，如果两个声优合作配音过一部动漫，则在两个节点（声优）之间有一条边。构建节点和边的数据结构，使用边列表的形式存储图的有关数据，并将格式化后的数据保存为**edge_info.txt**。实现见源文件中的**parse_data.py**，该文件中还有一些具有其他实用功能的函数。

* #### 权重计算

  使用公式
  $$
  weight=\frac{\sqrt{IndexFactor}}{\lg(ScoreFactor)}\times50
  $$
  计算每条边的权重。
  其中：

  * $ScoreFactor$为该边对应的动漫在百度百科中的浏览次数。
  * $IndexFactor=\frac{index(1)+index(2)}{length}$，$index(1)$和$index(2)$分别为该边对应的两个节点节点1与节点2对应的声优在该动漫声优表中的出现位置，$length$为该边对应动漫声优表的长度。

  $ScoreFactor$越大表明该边对应的动漫重要性越高，$IndexFactor$越小表明该边对应的声优出演的角色在动漫中重要性越高。$ScoreFactor$越大，$IndexFactor$越小，该边的权重($weight$)越小。

* #### 算法实现

  为了能够使用**Unity**实现算法结果的实时化显示，大作业的算法使用兼容**Unity**的**C#**编写。具体实现见**C#**源文件**program.cs**。具体而言，最短路径算法使用了**dijkstra**算法，而最小生成树算法使用了**prim**算法。算法就效率而言可能没有达到最优，但对于该大作业的数据规模（1600节点，130000边），运行时间可忽略不计。

* #### 可视化

## 程序操作方法



